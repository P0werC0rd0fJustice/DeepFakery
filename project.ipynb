{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tristan Breetz - Term Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Fake generation using an auto-encoder with discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use autoencoder to reduce input image to latent space and then resolve latent space back to output image.\n",
    "Then, using a discriminator network, calculate reconstruction accuracy by measuring against ground truth values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras import backend\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-encoder network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auto-encoder portion of the network will be 4 hidden layers where the middle is the smallest (the most compressed latent space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, w,h):\n",
    "        self.encoder = keras.Sequential()\n",
    "        self.encoder.add(keras.layers.Dense(128, input_dim=1200))\n",
    "        self.encoder.add(layers.Dense(128, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(64, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(128, activation='relu'))\n",
    "        self.encoder.add(layers.Dense(200, activation='softmax'))\n",
    "        self.encoder.add(layers.Dense(np.prod((w,h,3)), activation='softmax'))\n",
    "        self.encoder.compile(optimizer='adam', loss=self.wasserstein_loss)\n",
    "\n",
    "    #Generator networks often use the Wasserstein loss function\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return backend.mean(y_true * y_pred)\n",
    "    \n",
    "    def generate(self,count=1):\n",
    "        images = []\n",
    "        for i in range(count):\n",
    "            noises = []\n",
    "            noises.append(np.random.normal(size=(1,1200)))\n",
    "            print(noises)\n",
    "            image = encoder.predict(noises)\n",
    "            images.append(image.reshape(20,20,3))\n",
    "        return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator portion of the network is simple in function; it's job is to determine whether an input image was generated by the auto-encoder or if it is a ground truth image.\n",
    "\n",
    "The output of the discriminator is then feed into the auto-encoder as its loss function.\n",
    "\n",
    "The structure will have a 1 hidden layer with an output layer of just one scalar value that signifies the confidence of the discriminator's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self):\n",
    "        discriminator = keras.Sequential()\n",
    "        discriminator.add(keras.layers.Dense(256, input_shape=(20,20,3), activation='relu'))\n",
    "        discriminator.add(keras.layers.Dense(64, activation='relu'))\n",
    "        discriminator.add(keras.layers.Dense(1))\n",
    "        discriminator.compile(optimizer='adam',loss=self.wasserstein_loss)\n",
    "        \n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return backend.mean(y_true * y_pred)\n",
    "    \n",
    "    def predict(self, image):\n",
    "        return discriminator.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory of operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together, these networks create a GAN, a generative adversarial network. The two components are fighting against each other, the auto-encoder seeks to trick the discriminator and the discriminator seeks to not be tricked. In doing so, they both get better at their jobs, producing more and more accurate fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, w, h):\n",
    "        self.generator = Generator(w,h)\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "    def train(self, epochs):\n",
    "        #Take turn training generator and discriminator\n",
    "        for i in range(epochs):\n",
    "            if i % 2 == 0:\n",
    "                generator.train()\n",
    "            else:\n",
    "                discriminator.train()\n",
    "                \n",
    "    def import_dataset(self, image_dir):\n",
    "        return True\n",
    "    \n",
    "    def gen_image(self, image):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.09141122, -0.59820454,  0.81875091, ..., -0.64676362,\n",
      "         0.1330023 , -2.84266513]])]\n",
      "[array([[ 0.89595187,  2.72895173,  0.10348552, ..., -1.05556068,\n",
      "        -0.16748799, -1.10741326]])]\n",
      "[array([[ 0.02213038,  1.16376996, -0.96395037, ...,  0.51723481,\n",
      "        -0.25523965,  0.23920567]])]\n",
      "[array([[0.99881912, 0.65112111, 0.22180008, ..., 1.45484618, 1.20205215,\n",
      "        1.22209881]])]\n",
      "[array([[ 0.43136811,  0.6488859 ,  2.25641028, ...,  0.00945276,\n",
      "        -0.41321694,  0.77960794]])]\n",
      "[array([[ 1.50379919, -0.4602046 ,  0.24670862, ..., -0.39481692,\n",
      "         0.26663424, -1.91491707]])]\n",
      "[array([[-1.94435919,  1.01730985, -1.02858738, ..., -1.65975565,\n",
      "        -1.3775783 ,  0.68752084]])]\n",
      "[array([[-0.93047741,  0.11093246, -0.45165822, ..., -0.01725933,\n",
      "         0.90577823,  0.74476676]])]\n",
      "[array([[0.36448814, 0.41461328, 0.07361018, ..., 2.56831787, 0.02363201,\n",
      "        2.18862709]])]\n",
      "[array([[-0.59160368, -0.0766702 ,  0.91545636, ..., -0.07198228,\n",
      "         0.79508812,  0.87884924]])]\n"
     ]
    }
   ],
   "source": [
    "fake_images = gan.generator.generate(10) #Generate 10 fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 3)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a2cd40af0>"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fake_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
